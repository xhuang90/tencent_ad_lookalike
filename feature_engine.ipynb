{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:59:18.557514Z",
     "start_time": "2021-04-02T06:59:17.693288Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T06:59:27.760703Z",
     "start_time": "2021-04-02T06:59:27.757971Z"
    }
   },
   "outputs": [],
   "source": [
    "data_org_dir = 'data/data_tencent/'\n",
    "data_prep_dir = 'data/preprocess/'\n",
    "# data_prep_dir = 'data/sample/'\n",
    "sample_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:00:35.121661Z",
     "start_time": "2021-04-02T06:59:31.147663Z"
    }
   },
   "outputs": [],
   "source": [
    "if sample_test:\n",
    "    df_data = pd.read_csv(data_prep_dir + 'train_feat_merge_mini.csv')\n",
    "else:\n",
    "    df_data = pd.read_csv(data_prep_dir + 'train_feat_merge.csv')\n",
    "\n",
    "train_idx_lst = list(df_data[df_data['n_parts'] != 1].index)\n",
    "valid_idx_lst = list(df_data[df_data['n_parts'] == 1].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:00:35.136864Z",
     "start_time": "2021-04-02T07:00:35.124455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_parts', 'aid', 'uid', 'label', 'LBS', 'age', 'appIdAction',\n",
       "       'appIdInstall', 'carrier', 'consumptionAbility', 'ct', 'education',\n",
       "       'gender', 'house', 'interest1', 'interest2', 'interest3', 'interest4',\n",
       "       'interest5', 'kw1', 'kw2', 'kw3', 'marriageStatus', 'os', 'topic1',\n",
       "       'topic2', 'topic3', 'advertiserId', 'campaignId', 'creativeId',\n",
       "       'creativeSize', 'adCategoryId', 'productId', 'productType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:01:11.317150Z",
     "start_time": "2021-04-02T07:00:35.139861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_parts : 0.0 %\n",
      "aid : 0.0 %\n",
      "uid : 0.0 %\n",
      "label : 0.0 %\n",
      "LBS : 0.0 %\n",
      "age : 0.0 %\n",
      "appIdAction : 98.0 %\n",
      "appIdInstall : 98.0 %\n",
      "carrier : 0.0 %\n",
      "consumptionAbility : 0.0 %\n",
      "ct : 0.0 %\n",
      "education : 0.0 %\n",
      "gender : 0.0 %\n",
      "house : 0.0 %\n",
      "interest1 : 9.0 %\n",
      "interest2 : 34.0 %\n",
      "interest3 : 97.0 %\n",
      "interest4 : 98.0 %\n",
      "interest5 : 25.0 %\n",
      "kw1 : 10.0 %\n",
      "kw2 : 3.0 %\n",
      "kw3 : 95.0 %\n",
      "marriageStatus : 0.0 %\n",
      "os : 0.0 %\n",
      "topic1 : 9.0 %\n",
      "topic2 : 4.0 %\n",
      "topic3 : 95.0 %\n",
      "advertiserId : 0.0 %\n",
      "campaignId : 0.0 %\n",
      "creativeId : 0.0 %\n",
      "creativeSize : 0.0 %\n",
      "adCategoryId : 0.0 %\n",
      "productId : 0.0 %\n",
      "productType : 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# 缺失情况统计\n",
    "total = len(df_data)\n",
    "for col_name in list(df_data.columns):\n",
    "    df_missing = (df_data[df_data[col_name] == '-1'])\n",
    "    \n",
    "    print(col_name, ':', round(len(df_missing)/total, 2) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除特征\n",
    "\n",
    "1. 删除category特别大特别稀疏特征: 'appIdInstall', 'appIdAction', 'marriageStatus';\n",
    "2. 删除缺失情况严重特征: 'interest3', 'interest4', 'kw3', 'topic3';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:01:21.002684Z",
     "start_time": "2021-04-02T07:01:18.181281Z"
    }
   },
   "outputs": [],
   "source": [
    "feat2drop = ['appIdInstall', 'appIdAction', 'marriageStatus', 'interest3', 'interest4', 'kw3', 'topic3']\n",
    "df_data.drop(feat2drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:01:21.079043Z",
     "start_time": "2021-04-02T07:01:21.005155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_parts', 'aid', 'uid', 'label', 'LBS', 'age', 'carrier',\n",
       "       'consumptionAbility', 'ct', 'education', 'gender', 'house', 'interest1',\n",
       "       'interest2', 'interest5', 'kw1', 'kw2', 'os', 'topic1', 'topic2',\n",
       "       'advertiserId', 'campaignId', 'creativeId', 'creativeSize',\n",
       "       'adCategoryId', 'productId', 'productType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定长离散特征\n",
    "- 用户类: 'LBS', 'age', 'carrier', 'consumptionAbility', 'education', 'gender', 'house', 'os'\n",
    "- 广告类: 'aid', 'advertiserId', 'campaignId', 'creativeId', 'creativeSize', 'adCategoryId','productId', 'productType'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:02:30.566928Z",
     "start_time": "2021-04-02T07:01:26.875195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:03<00:00,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "discrete_feat_lst = ['LBS', 'age', 'carrier', 'consumptionAbility', 'education', 'gender', 'house', 'os',\n",
    "                     'aid', 'advertiserId', 'campaignId', 'creativeId', 'creativeSize', 'adCategoryId',\n",
    "                     'productId', 'productType']\n",
    "t0 = time.time()\n",
    "for discrete_feat in tqdm(discrete_feat_lst):\n",
    "    enc = LabelEncoder()\n",
    "    try:\n",
    "        df_data[discrete_feat] = enc.fit_transform(df_data[discrete_feat].apply(int))\n",
    "    except:\n",
    "        df_data[discrete_feat] = enc.fit_transform(df_data[discrete_feat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:07:45.815017Z",
     "start_time": "2021-04-02T07:02:33.014110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:57<00:00,  9.65s/it]\n",
      "100%|██████████| 5/5 [00:55<00:00, 11.15s/it]\n",
      "100%|██████████| 5/5 [00:55<00:00, 11.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocess/train_x_sparse_onehot.npz is saved! Array shape is (7038840, 1526)\n",
      "data/preprocess/valid_x_sparse_onehot.npz is saved! Array shape is (1759974, 1526)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encoding(df_feat2enc):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df_feat2enc:\n",
    "    :type df_feat2enc:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    \n",
    "    one_hot_enc.fit(df_feat2enc.values.reshape(-1, 1))\n",
    "    feat_enc_arr = one_hot_enc.transform(df_feat2enc.values.reshape(-1, 1))#.toarray()\n",
    "\n",
    "    return feat_enc_arr\n",
    "\n",
    "# 数据量太大了, 一下子肝不完, 必须分开\n",
    "discrete_feat_lst1 = ['LBS', 'age', 'carrier', 'consumptionAbility', 'education', 'gender']\n",
    "discrete_feat_lst2 = ['aid', 'advertiserId', 'campaignId', 'creativeId', 'creativeSize']\n",
    "discrete_feat_lst3 = ['adCategoryId', 'productId', 'productType', 'house', 'os']\n",
    "\n",
    "discrete_feat = [discrete_feat_lst1, discrete_feat_lst2, discrete_feat_lst3]\n",
    "# 初始化\n",
    "one_hot_enc = OneHotEncoder()\n",
    "\n",
    "x_train = pd.DataFrame()\n",
    "x_valid = pd.DataFrame()\n",
    "###### 数据量很大的时候用这个 ######\n",
    "for feat_lst in discrete_feat:\n",
    "    \n",
    "    for feat in tqdm(feat_lst):\n",
    "        # 合并训练\n",
    "        df_feat2enc = df_data[feat]\n",
    "        one_hot_enc.fit(df_feat2enc.values.reshape(-1, 1))\n",
    "        # 训练集\n",
    "        train2enc = df_data.loc[train_idx_lst][feat]\n",
    "        train_enc_arr = one_hot_enc.transform(train2enc.values.reshape(-1, 1))\n",
    "        x_train = sparse.hstack([x_train, train_enc_arr])\n",
    "        # 验证集\n",
    "        valid2enc = df_data.loc[valid_idx_lst][feat]\n",
    "        valid_enc_arr = one_hot_enc.transform(valid2enc.values.reshape(-1, 1))\n",
    "        x_valid = sparse.hstack([x_valid, valid_enc_arr])\n",
    "    \n",
    "train_f_dir = data_prep_dir + 'train_x_sparse_onehot.npz'\n",
    "sparse.save_npz(train_f_dir, x_train)\n",
    "\n",
    "valid_f_dir = data_prep_dir + 'valid_x_sparse_onehot.npz'\n",
    "sparse.save_npz(valid_f_dir, x_valid)\n",
    "\n",
    "print(train_f_dir, 'is saved! Array shape is', x_train.shape)\n",
    "print(valid_f_dir, 'is saved! Array shape is', x_valid.shape)\n",
    "\n",
    "###### 测试数据用这个 ######\n",
    "# train_x = np.empty([len(train_idx_lst), 1], dtype=int)\n",
    "# valid_x = np.empty([len(valid_idx_lst), 1], dtype=int) \n",
    "# for feat in tqdm(discrete_feat_lst):\n",
    "    \n",
    "#     # 训练集\n",
    "#     df_feat2enc_train = df_data.loc[train_idx_lst][feat]\n",
    "#     train_enc_arr = one_hot_encoding(df_feat2enc_train)\n",
    "#     train_x = sparse.hstack([train_x, train_enc_arr])\n",
    "#     # 验证集\n",
    "#     df_feat2enc_valid = df_data.loc[valid_idx_lst][feat]\n",
    "#     valid_enc_arr = one_hot_encoding(df_feat2enc_valid)\n",
    "#     valid_x = sparse.hstack([valid_x, valid_enc_arr])\n",
    "    \n",
    "# train_f_dir = data_prep_dir + 'train_x_sparse_onehot.npz'\n",
    "# sparse.save_npz(train_f_dir, train_enc_arr)\n",
    "\n",
    "# valid_f_dir = data_prep_dir + 'valid_x_sparse_onehot.npz'\n",
    "# sparse.save_npz(valid_f_dir, valid_enc_arr)\n",
    "\n",
    "# print(train_f_dir, 'is saved! Array shape is', train_x.shape)\n",
    "# print(valid_f_dir, 'is saved! Array shape is', valid_x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列型特征\n",
    "- 用户类: 'ct', 'interest1', 'interest2', 'interest5', 'kw1', 'kw2', 'os'，'topic1', 'topic2', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:07:45.820040Z",
     "start_time": "2021-04-02T07:07:45.817126Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_feat_lst = ['ct', 'interest1', 'interest2', 'interest5', 'kw1', 'kw2', 'topic1', 'topic2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建序列长度特征\n",
    "len_static_features = [x+'_len' for x in sequence_feat_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:11:25.649117Z",
     "start_time": "2021-04-02T07:09:51.189602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocess/train_x_sparse_seq_len.npz is saved! Array shape is (7038840, 8)\n",
      "data/preprocess/valid_x_sparse_seq_len.npz is saved! Array shape is (1759974, 8)\n"
     ]
    }
   ],
   "source": [
    "# 初始化\n",
    "x_train = pd.DataFrame()\n",
    "x_valid = pd.DataFrame()\n",
    "\n",
    "df_feat2len = df_data[sequence_feat_lst].applymap(lambda x: len(x.split(' ')))\n",
    "\n",
    "# 构建训练集&验证集\n",
    "df_train_enc = df_feat2len.loc[train_idx_lst].values\n",
    "df_valid_enc = df_feat2len.loc[valid_idx_lst].values\n",
    "\n",
    "x_train = sparse.hstack([x_train, df_train_enc])\n",
    "x_valid = sparse.hstack([x_valid, df_valid_enc])\n",
    "\n",
    "train_f_dir = data_prep_dir + 'train_x_sparse_seq_len.npz'\n",
    "sparse.save_npz(train_f_dir, x_train)\n",
    "\n",
    "valid_f_dir = data_prep_dir + 'valid_x_sparse_seq_len.npz'\n",
    "sparse.save_npz(valid_f_dir, x_valid)\n",
    "\n",
    "print(train_f_dir, 'is saved! Array shape is', x_train.shape)\n",
    "print(valid_f_dir, 'is saved! Array shape is', x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:09:17.372742Z",
     "start_time": "2021-04-02T07:09:17.368639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8798814, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat2len.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建序列count特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:34:21.856362Z",
     "start_time": "2021-04-02T07:11:32.271537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [18:57<00:00, 162.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocess/train_x_sparse_cntv.npz is saved! Array shape is (7038840, 323142)\n",
      "data/preprocess/valid_x_sparse_cntv.npz is saved! Array shape is (1759974, 323142)\n"
     ]
    }
   ],
   "source": [
    "# 初始化\n",
    "x_train = pd.DataFrame()\n",
    "x_valid = pd.DataFrame()\n",
    "cnt_enc = CountVectorizer()\n",
    "\n",
    "for sequence_feat in tqdm(sequence_feat_lst[1:]):  # TODO: 'ct'未构建该类特征\n",
    "    # 合并训练\n",
    "    df_feat2cnt = df_data[sequence_feat]\n",
    "    cnt_enc.fit(df_feat2cnt.values)\n",
    "    # 训练集\n",
    "    train2enc = df_data.loc[train_idx_lst][sequence_feat]\n",
    "    train_enc_arr = cnt_enc.transform(train2enc.values)\n",
    "    x_train = sparse.hstack([x_train, train_enc_arr])\n",
    "    # 验证集\n",
    "    valid2enc = df_data.loc[valid_idx_lst][sequence_feat]\n",
    "    valid_enc_arr = cnt_enc.transform(valid2enc.values)\n",
    "    x_valid = sparse.hstack([x_valid, valid_enc_arr])\n",
    "    \n",
    "train_f_dir = data_prep_dir + 'train_x_sparse_cntv.npz'\n",
    "sparse.save_npz(train_f_dir, x_train)\n",
    "\n",
    "valid_f_dir = data_prep_dir + 'valid_x_sparse_cntv.npz'\n",
    "sparse.save_npz(valid_f_dir, x_valid)\n",
    "\n",
    "print(train_f_dir, 'is saved! Array shape is', x_train.shape)\n",
    "print(valid_f_dir, 'is saved! Array shape is', x_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户id类特征\n",
    "- 用户类: 'uid'\n",
    "另外，因为也存在量大稀疏的问题，但是比赛的问题就是针对用户对广告的点击，因此uid对模型来说还是很有必要进行建模的，但是uid不使用category的方式建模，而是使用count和转化率建模：\n",
    "- uid_count : 对uid进行出现频次的建模。\n",
    "- uid_pos_count : 对uid进行正样本中的出现频次的建模。\n",
    "- uid_ad_features_pos_count : 对uid组合所有广告特征'ad_static_feature'进行正样本中的出现频次的建模。\n",
    "- 对uid进行如此多的建模方式是为了能对uid进行更加详细的表述，因为category的每一个特征就是一对一的，而count特征是多对一的，存在大量的信息损失，因此需要进行更多不同角度的建模，才能更好地表述uid。\n",
    "特征方面还有一些长尾处理，未出现id的统一映射，长度和count特征的未出现次数的取临近值等trick。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "### 加载&合并特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T07:36:06.491205Z",
     "start_time": "2021-04-02T07:35:15.025751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_sparse_onehot.npz (7038840, 1526)\n",
      "valid_x_sparse_onehot.npz (1759974, 1526)\n",
      "train_x_sparse_seq_len.npz (7038840, 8)\n",
      "valid_x_sparse_seq_len.npz (1759974, 8)\n",
      "train_x_sparse_cntv.npz (7038840, 323142)\n",
      "valid_x_sparse_cntv.npz (1759974, 323142)\n"
     ]
    }
   ],
   "source": [
    "feat_fname_train = ['train_x_sparse_onehot.npz', 'train_x_sparse_seq_len.npz', 'train_x_sparse_cntv.npz']\n",
    "feat_fname_valid = ['valid_x_sparse_onehot.npz', 'valid_x_sparse_seq_len.npz', 'valid_x_sparse_cntv.npz']\n",
    "x_train = pd.DataFrame()\n",
    "x_valid = pd.DataFrame()\n",
    "for tr, vl in zip(feat_fname_train, feat_fname_valid):\n",
    "    train_f = sparse.load_npz(data_prep_dir + tr).tocsr()  # [train_index,:]\n",
    "    valid_f = sparse.load_npz(data_prep_dir + vl).tocsr()  # [train_index,:]\n",
    "    print(tr, train_f.shape)\n",
    "    print(vl, valid_f.shape)\n",
    "#     print('读到了第',i,'个训练集特征文件')\n",
    "print(\"Sparse is ready\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:36:50.727728Z",
     "start_time": "2021-04-02T02:36:50.724144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_sparse_onehot.npz valid_x_sparse_onehot.npz\n",
      "train_x_sparse_seq_len.npz valid_x_sparse_seq_len.npz\n",
      "train_x_sparse_cntv.npz valid_x_sparse_cntv.npz\n"
     ]
    }
   ],
   "source": [
    "for tr, vl in zip(feat_fname_train, feat_fname_valid):\n",
    "#     print(tr, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:50:55.585066Z",
     "start_time": "2021-04-01T08:50:55.580515Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation(y_train, y_train_pred, y_test, y_test_pred, model_name=''):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_train:\n",
    "    :type y_train:\n",
    "    :param y_train_pred:\n",
    "    :type y_train_pred:\n",
    "    :param y_test:\n",
    "    :type y_test:\n",
    "    :param y_test_pred:\n",
    "    :type y_test_pred:\n",
    "    :param model_name:\n",
    "    :type model_name:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    print(\"{} Train AUC: {}, logloss: {}\".format(model_name, roc_auc_score(y_train, y_train_pred), log_loss(y_train, y_train_pred)))\n",
    "    # print(\"{} Train confusion matrix: {}\".format(model_name, confusion_matrix(y_train, y_train_pred)))\n",
    "\n",
    "    print(\"{} Test AUC: {}, logloss: {}\".format(model_name, roc_auc_score(y_test, y_test_pred), log_loss(y_test, y_test_pred)))\n",
    "    # print(\"{} Test confusion matrix: {}\".format(model_name, confusion_matrix(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:24:44.349050Z",
     "start_time": "2021-04-01T08:24:41.522539Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct y vector\n",
    "y_train = np.array(df_data[df_data['n_parts'] != 1]['label'])\n",
    "y_valid = np.array(df_data[df_data['n_parts'] == 1]['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline版本\n",
    "- 只使用离散特征，进行onehot编码\n",
    "- 线性模型：LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:50:44.637406Z",
     "start_time": "2021-04-01T08:25:06.735095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7038840, 1526) (1759974, 1526)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c7a591b41f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LogisticRegression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_valid.shape)\n",
    "# baseline版本\n",
    "turned_param = {\n",
    "        'penalty': 'l2',\n",
    "        'C': 10,\n",
    "        'solver': 'lbfgs',\n",
    "        'tol': 1e-4,\n",
    "        'max_iter': 10000\n",
    "    }\n",
    "\n",
    "clf = LogisticRegression(random_state=1, **turned_param)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_valid)\n",
    "\n",
    "model_evaluation(y_train, y_train_pred, y_valid, y_test_pred, model_name='LogisticRegression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:51:06.316029Z",
     "start_time": "2021-04-01T08:51:01.784218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Train AUC: 0.5000014816351326, logloss: 1.6558969428673103\n",
      "LogisticRegression Test AUC: 0.5, logloss: 1.6581997519647336\n"
     ]
    }
   ],
   "source": [
    "# 基于相似度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T10:26:08.694585Z",
     "start_time": "2021-03-31T10:26:08.626203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate([1,1,1]):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
